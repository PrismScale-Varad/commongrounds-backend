diff --git a/core/config.py b/core/config.py
index abcdef1..1234567 100644
--- a/core/config.py
+++ b/core/config.py
@@ -13,6 +13,7 @@ class Settings(BaseSettings):
     # JWT
     jwt_expiry_days: int = 180
     ALGORITHM: str = "HS256"
 
+    # OpenAI API
     OPENAI_API_KEY: str = os.getenv("OPENAI_API_KEY", "")
 
     # OAuth Settings for Google
 diff --git a/utils/chat.py b/utils/chat.py
new file mode 100644
index 0000000..abcdef2
+++ b/utils/chat.py
@@ -0,0 +1,27 @@
+import openai
+from core.config import settings
+import logging
+
+logger = logging.getLogger(__name__)
+
+openai.api_key = settings.OPENAI_API_KEY
+
+def generate_llm_response(message: str) -> str:
+    """
+    Generates a response from the OpenAI API based on the provided message.
+
+    Args:
+        message (str): The input message to send to the LLM.
+
+    Returns:
+        str: The response from the OpenAI API.
+    """
+    try:
+        response = openai.ChatCompletion.create(
+            model="gpt-3.5-turbo",  # or any other model you prefer
+            messages=[{"role": "user", "content": message}],
+            max_tokens=150  # adjust as per your needs
+        )
+        return response['choices'][0]['message']['content'].strip()
+    except Exception as e:
+        logger.error(f"Error while calling OpenAI API: {str(e)}")
+        return "I'm sorry, I couldn't generate a response at the moment."
